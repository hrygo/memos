# Code Review é—®é¢˜ä¿®å¤è®¡åˆ’

> åŸºäº main vs feat/ai-specs åˆ†æ”¯çš„å…¨é¢ Code Review
>
> **å®¡æŸ¥æ—¥æœŸ**: 2026-01-20
> **æ•´ä½“è¯„åˆ†**: 7.6/10
> **é—®é¢˜æ€»æ•°**: 26 ä¸ªï¼ˆP0: 2, P1: 8, P2: 6, P3: 10ï¼‰

---

## ğŸ“‹ ç›®å½•

- [P0 - å…³é”®é—®é¢˜ï¼ˆå¿…é¡»ä¿®å¤ï¼‰](#p0---å…³é”®é—®é¢˜å¿…é¡»ä¿®å¤)
- [P1 - é‡è¦é—®é¢˜ï¼ˆå¼ºçƒˆå»ºè®®ä¿®å¤ï¼‰](#p1---é‡è¦é—®é¢˜å¼ºçƒˆå»ºè®®ä¿®å¤)
- [P2 - æ€§èƒ½ä¼˜åŒ–ï¼ˆå»ºè®®æ”¹è¿›ï¼‰](#p2---æ€§èƒ½ä¼˜åŒ–å»ºè®®æ”¹è¿›)
- [P3 - ä»£ç è´¨é‡ï¼ˆå¯é€‰æ”¹è¿›ï¼‰](#p3---ä»£ç è´¨é‡å¯é€‰æ”¹è¿›)
- [æµ‹è¯•éªŒè¯æ¸…å•](#æµ‹è¯•éªŒè¯æ¸…å•)

---

## P0 - å…³é”®é—®é¢˜ï¼ˆå¿…é¡»ä¿®å¤ï¼‰

### P0-1: ä¿®å¤ LLM æµå¼å“åº” Goroutine æ³„æ¼

**ä¼˜å…ˆçº§**: ğŸ”´ ç´§æ€¥
**æ–‡ä»¶**: `plugin/ai/llm.go:92-121`
**é¢„ä¼°æ—¶é—´**: 30 åˆ†é’Ÿ

#### é—®é¢˜æè¿°

`ChatStream` æ–¹æ³•ä¸­å¯åŠ¨çš„ goroutine å¯èƒ½æ°¸è¿œä¸ä¼šé€€å‡ºï¼Œå¯¼è‡´èµ„æºæ³„æ¼ï¼š

1. å¦‚æœ `s.model.GenerateContent` åœ¨ `ctx.Done()` ä¹‹åä»ç„¶é˜»å¡ï¼Œgoroutine å°†æ°¸è¿œè¿è¡Œ
2. å¦‚æœ `contentChan` çš„æ¥æ”¶æ–¹æå‰é€€å‡ºï¼Œgoroutine ä¼šåœ¨å‘é€æ—¶æ°¸ä¹…é˜»å¡
3. ç¼ºå°‘è¶…æ—¶ä¿æŠ¤æœºåˆ¶

#### ä¿®å¤æ­¥éª¤

**æ­¥éª¤ 1**: ä¿®æ”¹ `plugin/ai/llm.go` çš„ `ChatStream` æ–¹æ³•

```go
func (s *llmService) ChatStream(ctx context.Context, messages []Message) (<-chan string, <-chan error) {
	// ä¿®æ”¹ç‚¹ 1: æ·»åŠ ç¼“å†²ï¼Œé˜²æ­¢å‘é€é˜»å¡
	contentChan := make(chan string, 10)
	errChan := make(chan error, 1)

	go func() {
		defer close(contentChan)
		defer close(errChan)

		llmMessages := convertMessages(messages)

		// ä¿®æ”¹ç‚¹ 2: æ·»åŠ è¶…æ—¶ä¿æŠ¤
		ctx, cancel := context.WithTimeout(ctx, 5*time.Minute)
		defer cancel()

		_, err := s.model.GenerateContent(ctx, llmMessages,
			llms.WithMaxTokens(s.maxTokens),
			llms.WithTemperature(float64(s.temperature)),
			llms.WithStreamingFunc(func(ctx context.Context, chunk []byte) error {
				// ä¿®æ”¹ç‚¹ 3: ä½¿ç”¨ select æ£€æŸ¥ context çŠ¶æ€
				select {
				case contentChan <- string(chunk):
					return nil
				case <-ctx.Done():
					return ctx.Err()
				}
			}),
		)

		if err != nil {
			select {
			case errChan <- err:
			case <-ctx.Done():
				// Context å·²å–æ¶ˆï¼Œæ— æ³•å‘é€é”™è¯¯
			}
		}
	}()

	return contentChan, errChan
}
```

**æ­¥éª¤ 2**: æ·»åŠ æµ‹è¯•éªŒè¯

åˆ›å»º `plugin/ai/llm_stream_test.go`:

```go
func TestLLMService_ChatStream_ContextCancellation(t *testing.T) {
	// ... æµ‹è¯• context å–æ¶ˆæ—¶ goroutine èƒ½æ­£ç¡®é€€å‡º
}

func TestLLMService_ChatStream_Timeout(t *testing.T) {
	// ... æµ‹è¯•è¶…æ—¶ä¿æŠ¤
}
```

**æ­¥éª¤ 3**: è¿è¡Œæµ‹è¯•éªŒè¯

```bash
cd plugin/ai
go test -v -run TestLLMService_ChatStream
```

#### éªŒè¯æ ‡å‡†

- âœ… Context å–æ¶ˆå goroutine èƒ½æ­£ç¡®é€€å‡º
- âœ… è¶…æ—¶åèƒ½è¿”å›é”™è¯¯
- âœ… å•å…ƒæµ‹è¯•é€šè¿‡
- âœ… æ—  goroutine æ³„æ¼ï¼ˆä½¿ç”¨ `runtime.NumGoroutine()` æ£€æŸ¥ï¼‰

---

### P0-2: Embedding Runner æ·»åŠ  Context å–æ¶ˆæ£€æŸ¥

**ä¼˜å…ˆçº§**: ğŸ”´ ç´§æ€¥
**æ–‡ä»¶**: `server/runner/embedding/runner.go:58-86`
**é¢„ä¼°æ—¶é—´**: 20 åˆ†é’Ÿ

#### é—®é¢˜æè¿°

`processNewMemos` æ–¹æ³•åœ¨æ‰¹é‡å¤„ç† embedding æ—¶æœªæ£€æŸ¥ `ctx.Done()`ï¼Œå¯èƒ½å¯¼è‡´ï¼š
- æœåŠ¡å…³é—­æ—¶é•¿æ—¶é—´é˜»å¡
- èµ„æºæ— æ³•åŠæ—¶é‡Šæ”¾
- ä¼˜é›…å…³é—­å¤±è´¥

#### ä¿®å¤æ­¥éª¤

**æ­¥éª¤ 1**: ä¿®æ”¹ `server/runner/embedding/runner.go` çš„ `processNewMemos` æ–¹æ³•

```go
func (r *Runner) processNewMemos(ctx context.Context) {
	memos, err := r.findMemosWithoutEmbedding(ctx)
	if err != nil {
		slog.Error("failed to find memos without embedding", "error", err)
		return
	}

	if len(memos) == 0 {
		return
	}

	slog.Info("processing memos for embedding", "count", len(memos))

	for i := 0; i < len(memos); i += r.batchSize {
		// ä¿®æ”¹ç‚¹: æ·»åŠ  context å–æ¶ˆæ£€æŸ¥
		select {
		case <-ctx.Done():
			slog.Info("embedding processing cancelled", "processed", i, "total", len(memos))
			return
		default:
			// ç»§ç»­å¤„ç†
		}

		end := i + r.batchSize
		if end > len(memos) {
			end = len(memos)
		}
		batch := memos[i:end]

		if err := r.processBatch(ctx, batch); err != nil {
			slog.Error("failed to process batch", "error", err, "batch", fmt.Sprintf("%d-%d", i, end))
			continue
		}
		slog.Info("batch processed", "count", len(batch), "progress", fmt.Sprintf("%d/%d", end, len(memos)))
	}
}
```

**æ­¥éª¤ 2**: åŒæ—¶æ£€æŸ¥ `processBatch` æ–¹æ³•

åœ¨ `processBatch` æ–¹æ³•å¼€å§‹å¤„ä¹Ÿæ·»åŠ æ£€æŸ¥ï¼š

```go
func (r *Runner) processBatch(ctx context.Context, memos []*store.Memo) error {
	// æ·»åŠ  context æ£€æŸ¥
	select {
	case <-ctx.Done():
		return ctx.Err()
	default:
	}

	// ... åŸæœ‰é€»è¾‘
}
```

**æ­¥éª¤ 3**: æ·»åŠ æµ‹è¯•

```go
func TestRunner_ProcessNewMemos_ContextCancellation(t *testing.T) {
	// æµ‹è¯• context å–æ¶ˆæ—¶èƒ½æ­£ç¡®åœæ­¢
}
```

#### éªŒè¯æ ‡å‡†

- âœ… æœåŠ¡å…³é—­æ—¶èƒ½ç«‹å³åœæ­¢å¤„ç†
- âœ… Context å–æ¶ˆæ—¥å¿—æ­£ç¡®è¾“å‡º
- âœ… ä¼˜é›…å…³é—­æµ‹è¯•é€šè¿‡

---

## P1 - é‡è¦é—®é¢˜ï¼ˆå¼ºçƒˆå»ºè®®ä¿®å¤ï¼‰

### P1-1: ç»Ÿä¸€åç«¯æ—¶åŒºå¤„ç†ä¸º UTC

**ä¼˜å…ˆçº§**: ğŸŸ  é«˜
**æ–‡ä»¶**: `plugin/ai/schedule/parser.go`
**é¢„ä¼°æ—¶é—´**: 45 åˆ†é’Ÿ

#### ä¿®å¤æ­¥éª¤

**æ­¥éª¤ 1**: ä¿®æ”¹ LLM promptï¼Œæ˜ç¡®è¦æ±‚ UTC æ—¶é—´

```go
systemPrompt := fmt.Sprintf(`You are an intelligent schedule parser...

Current Time (UTC): %s
User Timezone: %s

IMPORTANT RULES:
1. Always return start_time and end_time in UTC timezone
2. Format: YYYY-MM-DD HH:mm:ss (no timezone suffix)
3. Calculate times in UTC, then convert to the format above`,
	now.UTC().Format("2006-01-02 15:04:05"),
	p.location.String())
```

**æ­¥éª¤ 2**: ä¿®æ”¹æ—¶é—´è§£æé€»è¾‘

```go
parseTime := func(timeStr string) (int64, error) {
	// ç»Ÿä¸€è§£æä¸º UTC
	t, err := time.Parse("2006-01-02 15:04:05", timeStr)
	if err != nil {
		return 0, fmt.Errorf("failed to parse time: %w", err)
	}
	return t.Unix(), nil
}
```

**æ­¥éª¤ 3**: æ·»åŠ æ—¶é—´åˆç†æ€§éªŒè¯

```go
// éªŒè¯è§£æçš„æ—¶é—´ä¸åœ¨è¿‡å»å¤ªä¹…
if startTs < now.Add(-24*time.Hour).Unix() {
	return nil, fmt.Errorf("parsed start time is too far in the past: %d", startTs)
}

// éªŒè¯ç»“æŸæ—¶é—´ä¸æ—©äºå¼€å§‹æ—¶é—´
if endTs < startTs {
	return nil, fmt.Errorf("end time %d is before start time %d", endTs, startTs)
}
```

#### éªŒè¯æ ‡å‡†

- âœ… æ—¶åŒºè½¬æ¢æµ‹è¯•é€šè¿‡
- âœ… è·¨æ—¶åŒºç”¨æˆ·çœ‹åˆ°æ­£ç¡®æ—¶é—´
- âœ… è¾¹ç•Œæƒ…å†µå¤„ç†æ­£ç¡®ï¼ˆå¤ä»¤æ—¶ã€æœˆæœ«ç­‰ï¼‰

---

### P1-2: ä¼˜åŒ–æ—¥ç¨‹å®ä¾‹å±•å¼€æ€§èƒ½

**ä¼˜å…ˆçº§**: ğŸŸ  é«˜
**æ–‡ä»¶**: `server/router/api/v1/schedule_service.go`
**é¢„ä¼°æ—¶é—´**: 40 åˆ†é’Ÿ

#### ä¿®å¤æ­¥éª¤

**æ­¥éª¤ 1**: æ ¹æ® PageSize åŠ¨æ€é™åˆ¶å®ä¾‹æ•°

```go
// åœ¨ ListSchedules æ–¹æ³•ä¸­
maxTotalInstances := 100 // é»˜è®¤å€¼
if req.PageSize > 0 {
	maxTotalInstances = int(req.PageSize) * 2 // ç•™ä¸€äº›ä½™åœ°
}
if maxTotalInstances > 500 {
	maxTotalInstances = 500 // ç¡¬é™åˆ¶
}
```

**æ­¥éª¤ 2**: æ·»åŠ æˆªæ–­æ ‡å¿—åˆ°å“åº”

ä¿®æ”¹ `proto/api/v1/schedule_service.proto`:

```proto
message ListSchedulesResponse {
  repeated Schedule schedules = 1;
  bool truncated = 2;  // æ·»åŠ æ­¤å­—æ®µ
}
```

**æ­¥éª¤ 3**: åœ¨è¾¾åˆ°é™åˆ¶æ—¶è®¾ç½®æ ‡å¿—

```go
if len(expandedSchedules) >= maxTotalInstances {
	response.Truncated = true
	break
}
```

**æ­¥éª¤ 4**: æ·»åŠ æ—¥å¿—è­¦å‘Š

```go
if len(expandedSchedules) >= maxTotalInstances {
	slog.Warn("schedule instance expansion truncated",
		"count", len(expandedSchedules),
		"limit", maxTotalInstances)
}
```

#### éªŒè¯æ ‡å‡†

- âœ… å¤§é‡æ—¥ç¨‹æ—¶å“åº”æ—¶é—´ < 1s
- âœ… å‰ç«¯èƒ½æ­£ç¡®æ˜¾ç¤ºæˆªæ–­æç¤º
- âœ… åˆ†é¡µåŠŸèƒ½æ­£å¸¸å·¥ä½œ

---

### P1-3: å‘é‡æœç´¢æ·»åŠ è¾“å…¥éªŒè¯

**ä¼˜å…ˆçº§**: ğŸŸ  é«˜
**æ–‡ä»¶**: `server/router/api/v1/ai_service.go`
**é¢„ä¼°æ—¶é—´**: 30 åˆ†é’Ÿ

#### ä¿®å¤æ­¥éª¤

**æ­¥éª¤ 1**: æ·»åŠ å¸¸é‡å®šä¹‰

```go
const (
	maxQueryLength = 1000
	minQueryLength = 2
)
```

**æ­¥éª¤ 2**: å®ç°è¾“å…¥æ¸…ç†å‡½æ•°

```go
func sanitizeQuery(query string) string {
	// ç§»é™¤å¤šä½™ç©ºç™½
	query = strings.TrimSpace(query)
	query = strings.Join(strings.Fields(query), " ")

	// ç§»é™¤æ§åˆ¶å­—ç¬¦
	query = strings.Map(func(r rune) rune {
		if r < 32 && r != '\n' && r != '\t' {
			return -1
		}
		return r
	}, query)

	return query
}
```

**æ­¥éª¤ 3**: åœ¨ `SemanticSearch` æ–¹æ³•ä¸­æ·»åŠ éªŒè¯

```go
func (s *AIService) SemanticSearch(ctx context.Context, req *v1pb.SemanticSearchRequest) (*v1pb.SemanticSearchResponse, error) {
	// éªŒè¯éç©º
	if req.Query == "" {
		return nil, status.Errorf(codes.InvalidArgument, "query is required")
	}

	// éªŒè¯é•¿åº¦
	if len(req.Query) > maxQueryLength {
		return nil, status.Errorf(codes.InvalidArgument,
			"query too long: maximum %d characters, got %d", maxQueryLength, len(req.Query))
	}

	if len(strings.TrimSpace(req.Query)) < minQueryLength {
		return nil, status.Errorf(codes.InvalidArgument,
			"query too short: minimum %d characters", minQueryLength)
	}

	// æ¸…ç†è¾“å…¥
	query := sanitizeQuery(req.Query)

	// Vectorize the query
	queryVector, err := s.EmbeddingService.Embed(ctx, query)
	if err != nil {
		return nil, status.Errorf(codes.Internal, "failed to process query")
	}

	// ... åç»­é€»è¾‘
}
```

**æ­¥éª¤ 4**: æ·»åŠ æµ‹è¯•

```go
func TestAIService_SemanticSearch_InputValidation(t *testing.T) {
	tests := []struct {
		name    string
		query   string
		wantErr bool
	}{
		{"empty query", "", true},
		{"too long", strings.Repeat("a", 1001), true},
		{"too short", "a", true},
		{"valid query", "test query", false},
		{"with extra spaces", "  test   query  ", false},
	}
	// ... æµ‹è¯•é€»è¾‘
}
```

#### éªŒè¯æ ‡å‡†

- âœ… ç©ºæŸ¥è¯¢è¢«æ‹’ç»
- âœ… è¶…é•¿æŸ¥è¯¢è¢«æ‹’ç»
- âœ… è¾“å…¥è¢«æ­£ç¡®æ¸…ç†
- âœ… å•å…ƒæµ‹è¯•é€šè¿‡

---

### P1-4: SQL æŸ¥è¯¢ä½¿ç”¨å ä½ç¬¦

**ä¼˜å…ˆçº§**: ğŸŸ  é«˜
**æ–‡ä»¶**: `store/db/postgres/memo_embedding.go`
**é¢„ä¼°æ—¶é—´**: 25 åˆ†é’Ÿ

#### ä¿®å¤æ­¥éª¤

**æ­¥éª¤ 1**: ä¿®æ”¹ `VectorSearch` æ–¹æ³•

```go
// ç¬¬ 122-133 è¡Œ
query := `
	SELECT
		memo.id, memo.creator_id, memo.created_ts, memo.updated_ts,
		memo.content, memo.visibility, memo.tags, memo.pinned,
		1 - (memo.embedding <=> $1) AS similarity
	FROM memo
	WHERE memo.creator_id = $2
		AND memo.embedding_model = $3
		AND memo.embedding IS NOT NULL
		AND (memo.visibility = 'PUBLIC' OR memo.creator_id = $2)
		AND memo.embedding <=> $1 < $4
	ORDER BY memo.embedding <=> $1
	LIMIT $5
`

rows, err := d.db.QueryContext(ctx, query,
	vector,           // $1
	opts.UserID,      // $2
	model,            // $3
	threshold,        // $4
	limit,            // $5 ä¿®æ”¹ç‚¹ï¼šä½¿ç”¨å ä½ç¬¦
)
```

**æ­¥éª¤ 2**: ä¿®æ”¹ `FindMemosWithoutEmbedding` æ–¹æ³•

```go
// ç¬¬ 204-210 è¡Œ
query := `
	SELECT id, content
	FROM memo
	WHERE creator_id = $1
		AND (embedding IS NULL OR embedding_model != $2)
	ORDER BY created_ts DESC
	LIMIT $3
`

rows, err := d.db.QueryContext(ctx, query,
	find.UserID,    // $1
	find.Model,     // $2
	limit,          // $3 ä¿®æ”¹ç‚¹ï¼šä½¿ç”¨å ä½ç¬¦
)
```

**æ­¥éª¤ 3**: åŒæ ·ä¿®æ”¹ MySQL å’Œ SQLite ç‰ˆæœ¬

- `store/db/mysql/memo_embedding.go`
- `store/db/sqlite/memo_embedding.go`

**æ­¥éª¤ 4**: è¿è¡Œæµ‹è¯•

```bash
go test ./store/db/... -v -run TestMemoEmbedding
```

#### éªŒè¯æ ‡å‡†

- âœ… æ‰€æœ‰æ•°æ®åº“å±‚çš„æµ‹è¯•é€šè¿‡
- âœ… SQL æ³¨å…¥æ‰«æå·¥å…·æ— è­¦å‘Š
- âœ… æŸ¥è¯¢ç»“æœæ­£ç¡®

---

### P1-5: å‰ç«¯æ·»åŠ æ—¶åŒºæ”¯æŒ

**ä¼˜å…ˆçº§**: ğŸŸ  é«˜
**æ–‡ä»¶**: `web/src/components/AIChat/ScheduleInput.tsx`
**é¢„ä¼°æ—¶é—´**: 1 å°æ—¶

#### ä¿®å¤æ­¥éª¤

**æ­¥éª¤ 1**: å®‰è£… dayjs æ—¶åŒºæ’ä»¶

```bash
cd web
npm install dayjs
```

**æ­¥éª¤ 2**: é…ç½® dayjs æ’ä»¶

åˆ›å»º `web/src/utils/dayjs.ts`:

```typescript
import dayjs from 'dayjs';
import utc from 'dayjs/plugin/utc';
import timezone from 'dayjs/plugin/timezone';

dayjs.extend(utc);
dayjs.extend(timezone);

export default dayjs;
```

**æ­¥éª¤ 3**: è·å–ç”¨æˆ·æ—¶åŒº

åœ¨ç”¨æˆ· store ä¸­æ·»åŠ æ—¶åŒºè®¾ç½®ï¼š

```typescript
// web/src/store/user.ts
export const useUserStore = create<UserState>((set) => ({
  // ... å…¶ä»–çŠ¶æ€
  timezone: Intl.DateTimeFormat().resolvedOptions().timeZone || 'Asia/Shanghai',
  setTimezone: (timezone: string) => set({ timezone }),
}));
```

**æ­¥éª¤ 4**: ä¿®æ”¹ ScheduleInput ç»„ä»¶

```typescript
import dayjs from '@/utils/dayjs';

const ScheduleInput = ({ ... }) => {
  const userTimezone = useUserStore(state => state.timezone) || 'Asia/Shanghai';

  // æ˜¾ç¤ºæ—¶é—´æ—¶è½¬æ¢åˆ°ç”¨æˆ·æ—¶åŒº
  const formatDateTime = (timestamp: bigint) => {
    return dayjs.unix(Number(timestamp))
      .tz(userTimezone)
      .format('YYYY-MM-DDTHH:mm');
  };

  // æäº¤æ—¶è½¬æ¢å› UTC
  const handleTimeChange = (field: 'startTs' | 'endTs', value: string) => {
    const ts = BigInt(dayjs.tz(value, userTimezone).unix());
    setParsedSchedule({ ...parsedSchedule, [field]: ts });
  };

  // ...
};
```

**æ­¥éª¤ 5**: æ·»åŠ æ—¶åŒºé€‰æ‹©å™¨åˆ°ç”¨æˆ·è®¾ç½®

```typescript
// web/src/components/UserSettings.tsx
const timezoneOptions = [
  'Asia/Shanghai',
  'Asia/Tokyo',
  'America/New_York',
  'Europe/London',
  // ... æ›´å¤šæ—¶åŒº
];

<Select value={timezone} onValueChange={setTimezone}>
  {timezoneOptions.map(tz => (
    <option key={tz} value={tz}>{tz}</option>
  ))}
</Select>
```

#### éªŒè¯æ ‡å‡†

- âœ… ä¸åŒæ—¶åŒºç”¨æˆ·çœ‹åˆ°æ­£ç¡®æ—¶é—´
- âœ… æ—¶åŒºåˆ‡æ¢åæ—¶é—´æ­£ç¡®æ›´æ–°
- âœ… æäº¤åˆ°åç«¯çš„æ—¶é—´æ˜¯ UTC

---

### P1-6: Reranker HTTP æ·»åŠ è¶…æ—¶

**ä¼˜å…ˆçº§**: ğŸŸ  é«˜
**æ–‡ä»¶**: `plugin/ai/reranker.go`
**é¢„ä¼°æ—¶é—´**: 15 åˆ†é’Ÿ

#### ä¿®å¤æ­¥éª¤

**æ­¥éª¤ 1**: ä¿®æ”¹ `NewRerankerService` å‡½æ•°

```go
func NewRerankerService(cfg *RerankerConfig) RerankerService {
	return &rerankerService{
		enabled: cfg.Enabled,
		apiKey:  cfg.APIKey,
		baseURL: strings.TrimSuffix(cfg.BaseURL, "/"),
		model:   cfg.Model,
		client: &http.Client{
			// ä¿®æ”¹ç‚¹ï¼šæ·»åŠ è¶…æ—¶
			Timeout: 30 * time.Second,
			// æ·»åŠ è¿æ¥æ± é…ç½®
			Transport: &http.Transport{
				MaxIdleConns:        100,
				MaxIdleConnsPerHost: 10,
				IdleConnTimeout:     90 * time.Second,
				// ç¦ç”¨ HTTP/2ï¼ˆé¿å…è¿æ¥å¤ç”¨é—®é¢˜ï¼‰
				ForceAttemptHTTP2:   false,
			},
		},
	}
}
```

**æ­¥éª¤ 2**: æ·»åŠ è¶…æ—¶æµ‹è¯•

```go
func TestRerankerService_Timeout(t *testing.T) {
	if testing.Short() {
		t.Skip("skipping timeout test in short mode")
	}

	// å¯åŠ¨ä¸€ä¸ªå»¶è¿Ÿå“åº”çš„æœåŠ¡
	server := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
		time.Sleep(35 * time.Second)
		w.WriteHeader(http.StatusOK)
	}))
	defer server.Close()

	cfg := &RerankerConfig{
		Enabled: true,
		APIKey:  "test-key",
		BaseURL: server.URL,
		Model:   "test-model",
	}
	svc := NewRerankerService(cfg)

	// åº”è¯¥è¶…æ—¶
	ctx, cancel := context.WithTimeout(context.Background(), 40*time.Second)
	defer cancel()

	docs := []Document{{Content: "test"}}
	_, err := svc.Rerank(ctx, docs, "test")

	require.Error(t, err)
	assert.Contains(t, err.Error(), "timeout")
}
```

#### éªŒè¯æ ‡å‡†

- âœ… è¶…æ—¶æµ‹è¯•é€šè¿‡
- âœ… æ­£å¸¸è¯·æ±‚ä¸å—å½±å“
- âœ… é”™è¯¯æ—¥å¿—è®°å½•è¶…æ—¶äº‹ä»¶

---

### P1-7: åˆ›å»ºæ•°æ®åº“è¿ç§»å›æ»šè„šæœ¬

**ä¼˜å…ˆçº§**: ğŸŸ  é«˜
**æ–‡ä»¶**: `store/migration/`
**é¢„ä¼°æ—¶é—´**: 50 åˆ†é’Ÿ

#### ä¿®å¤æ­¥éª¤

**æ­¥éª¤ 1**: åˆ›å»º PostgreSQL å›æ»šè„šæœ¬

åˆ›å»º `store/migration/postgres/0.26/down/1__add_schedule.sql`:

```sql
-- ===== Down Migration for 0.26 =====
-- å›æ»šæ—¥ç¨‹è¡¨

-- åˆ é™¤æ›´æ–°æ—¶é—´è§¦å‘å™¨
DROP TRIGGER IF EXISTS trigger_schedule_updated_ts ON schedule;
DROP FUNCTION IF EXISTS update_schedule_updated_ts();

-- åˆ é™¤ç´¢å¼•
DROP INDEX IF EXISTS idx_schedule_uid;
DROP INDEX IF EXISTS idx_schedule_start_ts;
DROP INDEX IF EXISTS idx_schedule_creator_status;
DROP INDEX IF EXISTS idx_schedule_creator_start;
DROP INDEX IF EXISTS idx_schedule_updated_ts;

-- åˆ é™¤è¡¨ï¼ˆçº§è”åˆ é™¤æé†’ï¼‰
DROP TABLE IF EXISTS schedule_reminder;
DROP TABLE IF EXISTS schedule;

-- è®°å½•æ—¥å¿—
DO $$
BEGIN
	RAISE NOTICE 'Down migration 0.26 completed: schedule tables dropped';
END $$;
```

**æ­¥éª¤ 2**: åˆ›å»º MySQL å›æ»šè„šæœ¬

åˆ›å»º `store/migration/mysql/0.26/down/1__add_schedule.sql`:

```sql
-- åˆ é™¤è§¦å‘å™¨
DROP TRIGGER IF EXISTS trigger_schedule_updated_ts ON schedule;
DROP FUNCTION IF EXISTS update_schedule_updated_ts;

-- åˆ é™¤ç´¢å¼•
DROP INDEX IF EXISTS idx_schedule_uid ON schedule;
DROP INDEX IF EXISTS idx_schedule_start_ts ON schedule;
DROP INDEX IF EXISTS idx_schedule_creator_status ON schedule;
DROP INDEX IF EXISTS idx_schedule_creator_start ON schedule;

-- åˆ é™¤è¡¨
DROP TABLE IF EXISTS schedule_reminder;
DROP TABLE IF EXISTS schedule;
```

**æ­¥éª¤ 3**: åˆ›å»º SQLite å›æ»šè„šæœ¬

åˆ›å»º `store/migration/sqlite/0.26/down/1__add_schedule.sql`:

```sql
-- SQLite ä¸æ”¯æŒ DROP TRIGGER IF EXISTSï¼Œç›´æ¥é‡å»ºè¡¨
DROP TABLE IF EXISTS schedule_reminder;
DROP TABLE IF EXISTS schedule;
```

**æ­¥éª¤ 4**: åˆ›å»º pgvector å›æ»šè„šæœ¬

åˆ›å»º `store/migration/postgres/0.30/down/1__add_pgvector.sql`:

```sql
-- åˆ é™¤å‘é‡ç›¸ä¼¼åº¦æœç´¢çš„å‡½æ•°
DROP FUNCTION IF EXISTS memo_similarity_search CASCADE;

-- åˆ é™¤ pgvector æ‰©å±•ï¼ˆè°¨æ…ï¼è¿™ä¼šå½±å“æ‰€æœ‰ä½¿ç”¨ pgvector çš„è¡¨ï¼‰
-- æ³¨æ„ï¼šåªåœ¨æ²¡æœ‰å…¶ä»–è¡¨ä½¿ç”¨ pgvector æ—¶æ‰æ‰§è¡Œ
-- DROP EXTENSION IF EXISTS vector CASCADE;

-- è€Œæ˜¯åªåˆ é™¤ç´¢å¼•
DROP INDEX IF EXISTS memo_embedding_idx;
DROP INDEX IF EXISTS memo_embedding_model_idx;

-- è®°å½•æ—¥å¿—
DO $$
BEGIN
	RAISE NOTICE 'Down migration 0.30 completed: vector indexes dropped';
	RAISE NOTICE 'To drop vector extension, manually run: DROP EXTENSION IF EXISTS vector CASCADE;';
END $$;
```

**æ­¥éª¤ 5**: æµ‹è¯•å›æ»š

```bash
# PostgreSQL
go run cmd/memos/main.go --mode migration --database postgres --down

# MySQL
go run cmd/memos/main.go --mode migration --database mysql --down

# SQLite
go run cmd/memos/main.go --mode migration --database sqlite --down
```

#### éªŒè¯æ ‡å‡†

- âœ… å›æ»šè„šæœ¬æ— è¯­æ³•é”™è¯¯
- âœ… å›æ»šåæ•°æ®åº“ schema æ­£ç¡®
- âœ… èƒ½é‡æ–°åº”ç”¨è¿ç§»

---

### P1-8: AI èŠå¤©æ·»åŠ é€Ÿç‡é™åˆ¶

**ä¼˜å…ˆçº§**: ğŸŸ  é«˜
**æ–‡ä»¶**: `server/router/api/v1/`
**é¢„ä¼°æ—¶é—´**: 1.5 å°æ—¶

#### ä¿®å¤æ­¥éª¤

**æ­¥éª¤ 1**: åˆ›å»ºé€Ÿç‡é™åˆ¶ä¸­é—´ä»¶

åˆ›å»º `server/middleware/rate_limit.go`:

```go
package middleware

import (
	"context"
	"sync"
	"time"

	"golang.org/x/time/rate"
	"google.golang.org/grpc/codes"
	"google.golang.org/grpc/status"
)

type RateLimiter struct {
	mu     sync.RWMutex
	limits map[string]*rate.Limiter
}

func NewRateLimiter() *RateLimiter {
	return &RateLimiter{
		limits: make(map[string]*rate.Limiter),
	}
}

func (rl *RateLimiter) getLimiter(userID string) *rate.Limiter {
	rl.mu.Lock()
	defer rl.mu.Unlock()

	if limiter, ok := rl.mu.limits[userID]; ok {
		return limiter
	}

	// æ¯ç§’ 10 ä¸ªè¯·æ±‚ï¼Œå…è®¸çªå‘ 20 ä¸ª
	limiter := rate.NewLimiter(rate.Every(time.Second/10), 20)
	rl.mu.limits[userID] = limiter
	return limiter
}

func (rl *RateLimiter) Allow(userID string) bool {
	return rl.getLimiter(userID).Allow()
}

// å…¨å±€é™æµå™¨
var globalAILimiter = NewRateLimiter()
```

**æ­¥éª¤ 2**: ä¿®æ”¹ `ai_service.go`

```go
func (s *AIService) ChatWithMemos(req *v1pb.ChatWithMemosRequest, stream v1pb.AIService_ChatWithMemosServer) error {
	ctx := stream.Context()

	// è·å–å½“å‰ç”¨æˆ·
	user, err := getCurrentUser(ctx, s.Store)
	if err != nil {
		return status.Errorf(codes.Unauthenticated, "unauthorized")
	}

	// æ£€æŸ¥é€Ÿç‡é™åˆ¶
	if !globalAILimiter.Allow(user.ID) {
		return status.Errorf(codes.ResourceExhausted,
			"rate limit exceeded: please wait before making another request")
	}

	// æ£€æŸ¥æ¯æ—¥é…é¢
	quota, err := s.Store.CheckUserQuota(ctx, user.ID, "ai_chat_daily")
	if err != nil {
		slog.Error("failed to check quota", "user", user.ID, "error", err)
		// ç»§ç»­å¤„ç†ï¼Œä½†è®°å½•é”™è¯¯
	}

	if quota != nil && quota.Remaining <= 0 {
		return status.Errorf(codes.ResourceExhausted,
			"daily quota exceeded: you have used all your AI chat credits for today")
	}

	// ... ç»§ç»­å¤„ç†èŠå¤©è¯·æ±‚

	// æˆåŠŸåæ‰£å‡é…é¢
	if quota != nil {
		if err := s.Store.DecrementQuota(ctx, user.ID, "ai_chat_daily", 1); err != nil {
			slog.Error("failed to decrement quota", "user", user.ID, "error", err)
		}
	}

	return nil
}
```

**æ­¥éª¤ 3**: æ·»åŠ é…é¢è¡¨åˆ°æ•°æ®åº“

åˆ›å»ºè¿ç§»è„šæœ¬ `store/migration/postgres/0.31/1__add_quota.sql`:

```sql
CREATE TABLE IF NOT EXISTS user_quota (
    id BIGSERIAL PRIMARY KEY,
    user_id BIGINT NOT NULL,
    quota_type VARCHAR(50) NOT NULL,
    daily_limit INTEGER NOT NULL DEFAULT 100,
    used_today INTEGER NOT NULL DEFAULT 0,
    reset_date DATE NOT NULL DEFAULT CURRENT_DATE,
    created_ts BIGINT NOT NULL EXTRACT(EPOCH FROM NOW()) * 1000,
    updated_ts BIGINT NOT NULL EXTRACT(EPOCH FROM NOW()) * 1000,
    UNIQUE(user_id, quota_type)
);

CREATE INDEX idx_user_quota_user_type ON user_quota(user_id, quota_type);

COMMENT ON TABLE user_quota IS 'User API quota tracking';
COMMENT ON COLUMN user_quota.quota_type IS 'Quota type: ai_chat_daily, semantic_search_daily, etc.';
```

**æ­¥éª¤ 4**: åœ¨ store ä¸­æ·»åŠ é…é¢æŸ¥è¯¢æ–¹æ³•

ä¿®æ”¹ `store/user.go`:

```go
func (s *Store) CheckUserQuota(ctx context.Context, userID int32, quotaType string) (*Quota, error) {
	// å®ç°é…é¢æ£€æŸ¥é€»è¾‘
}

func (s *Store) DecrementQuota(ctx context.Context, userID int32, quotaType string, amount int32) error {
	// å®ç°é…é¢æ‰£å‡é€»è¾‘
}
```

**æ­¥éª¤ 5**: æ·»åŠ æµ‹è¯•

```go
func TestRateLimiter(t *testing.T) {
	limiter := NewRateLimiter()

	// å¿«é€Ÿè¿ç»­è¯·æ±‚
	for i := 0; i < 25; i++ {
		allowed := limiter.Allow("user1")
		if i < 20 {
			assert.True(t, allowed, "request %d should be allowed", i)
		} else {
			assert.False(t, allowed, "request %d should be rate limited", i)
		}
	}
}
```

#### éªŒè¯æ ‡å‡†

- âœ… é€Ÿç‡é™åˆ¶æ­£å¸¸å·¥ä½œ
- âœ… é…é¢æ‰£å‡æ­£ç¡®
- âœ… ç”¨æˆ·æ”¶åˆ°å‹å¥½çš„é”™è¯¯æ¶ˆæ¯
- âœ… å•å…ƒæµ‹è¯•é€šè¿‡

---

## P2 - æ€§èƒ½ä¼˜åŒ–ï¼ˆå»ºè®®æ”¹è¿›ï¼‰

### P2-1: å‘é‡æŸ¥è¯¢ç¼“å­˜

**ä¼˜å…ˆçº§**: ğŸŸ¡ ä¸­
**é¢„ä¼°æ—¶é—´**: 2 å°æ—¶

#### å®ç°å»ºè®®

```go
// åˆ›å»ºç¼“å­˜å±‚
type SemanticSearchCache struct {
	cache *cache.Cache
	ttl   time.Duration
}

func NewSemanticSearchCache() *SemanticSearchCache {
	return &SemanticSearchCache{
		cache: cache.New(5*time.Minute, 10*time.Minute),
		ttl:   5 * time.Minute,
	}
}

func (c *SemanticSearchCache) Get(userID int32, query string) (*SearchResult, bool) {
	key := fmt.Sprintf("search:%d:%s", userID, hashQuery(query))
	if val, found := c.cache.Get(key); found {
		return val.(*SearchResult), true
	}
	return nil, false
}

func (c *SemanticSearchCache) Set(userID int32, query string, result *SearchResult) {
	key := fmt.Sprintf("search:%d:%s", userID, hashQuery(query))
	c.cache.Set(key, result, c.ttl)
}
```

---

### P2-2: Embedding æ‰¹å¤§å°åŠ¨æ€è°ƒæ•´

**ä¼˜å…ˆçº§**: ğŸŸ¡ ä¸­
**é¢„ä¼°æ—¶é—´**: 1.5 å°æ—¶

#### å®ç°å»ºè®®

```go
type Runner struct {
	// ... å…¶ä»–å­—æ®µ
	batchSize    int
	minBatchSize int
	maxBatchSize int
	lastDuration time.Duration
}

func (r *Runner) adjustBatchSize() {
	targetDuration := 3 * time.Second

	if r.lastDuration < targetDuration/2 {
		// å“åº”å¾ˆå¿«ï¼Œå¢åŠ æ‰¹å¤§å°
		r.batchSize = min(r.batchSize*2, r.maxBatchSize)
	} else if r.lastDuration > targetDuration*2 {
		// å“åº”æ…¢ï¼Œå‡å°‘æ‰¹å¤§å°
		r.batchSize = max(r.batchSize/2, r.minBatchSize)
	}

	slog.Info("adjusted batch size", "new_size", r.batchSize, "last_duration", r.lastDuration)
}
```

---

### P2-3: å‰ç«¯è™šæ‹ŸåŒ–

**ä¼˜å…ˆçº§**: ğŸŸ¡ ä¸­
**é¢„ä¼°æ—¶é—´**: 1 å°æ—¶

#### å®ç°å»ºè®®

```bash
npm install react-virtuoso
```

```typescript
import { Virtuoso } from 'react-virtuoso';

<Virtuoso
  style={{ height: '100%' }}
  data={messages}
  itemContent={(index, message) => (
    <MessageBubble key={index} message={message} />
  )}
/>
```

---

### P2-4: å»¶è¿Ÿå±•å¼€é‡å¤æ—¥ç¨‹

**ä¼˜å…ˆçº§**: ğŸŸ¡ ä¸­
**é¢„ä¼°æ—¶é—´**: 1 å°æ—¶

#### å®ç°å»ºè®®

ä¿®æ”¹ APIï¼Œæ·»åŠ  `expand_instances` å‚æ•°ï¼š

```proto
message ListSchedulesRequest {
  // ... å…¶ä»–å­—æ®µ
  bool expand_instances = 10;  // æ˜¯å¦å±•å¼€é‡å¤å®ä¾‹
}
```

é»˜è®¤è¿”å›é‡å¤è§„åˆ™ï¼Œå‰ç«¯æŒ‰éœ€å±•å¼€ï¼š

```typescript
const expandInstances = (schedule: Schedule, startDate: Date, endDate: Date) => {
  if (!schedule.recurrenceRule) return [schedule];

  const rule = JSON.parse(schedule.recurrenceRule);
  // å‰ç«¯è®¡ç®—å®ä¾‹
  return generateInstances(rule, schedule.startTs, startDate, endDate);
};
```

---

### P2-5: æ•°æ®åº“è¿æ¥æ± è°ƒä¼˜

**ä¼˜å…ˆçº§**: ğŸŸ¡ ä¸­
**é¢„ä¼°æ—¶é—´**: 30 åˆ†é’Ÿ

#### å®ç°å»ºè®®

```go
// store/db/postgres/common.go
db.SetMaxOpenConns(10)  // 2C ç¯å¢ƒï¼Œé™ä½å¹¶å‘è¿æ¥
db.SetMaxIdleConns(5)
db.SetConnMaxLifetime(1 * time.Hour)
db.SetConnMaxIdleTime(10 * time.Minute)
```

---

### P2-6: å›¾ç‰‡æ‡’åŠ è½½

**ä¼˜å…ˆçº§**: ğŸŸ¡ ä¸­
**é¢„ä¼°æ—¶é—´**: 20 åˆ†é’Ÿ

#### å®ç°å»ºè®®

```typescript
<img
  src={src}
  loading="lazy"
  decoding="async"
  alt={alt}
/>
```

---

## P3 - ä»£ç è´¨é‡ï¼ˆå¯é€‰æ”¹è¿›ï¼‰

### P3-1: å®šä¹‰å¸¸é‡

åˆ›å»º `plugin/ai/constants.go`:

```go
const (
	// Embedding
	DefaultEmbeddingModel     = "text-embedding-3-small"
	DefaultEmbeddingDimension = 1024

	// Reranker
	DefaultRerankerThreshold = 0.5
	DefaultRerankerTopK      = 100

	// Schedule
	MaxReminders          = 100
	MaxScheduleTitleLength = 200
	DefaultQueryWindowDays = 30
)
```

---

### P3-2: é”™è¯¯ç å›½é™…åŒ–

åˆ›å»º `server/errors/codes.go`:

```go
package errors

const (
	ErrScheduleTitleRequired    = "SCHEDULE_001"
	ErrScheduleInvalidName      = "SCHEDULE_002"
	ErrScheduleTimeConflict     = "SCHEDULE_003"
	ErrRateLimitExceeded        = "RATE_001"
	ErrQuotaExceeded            = "QUOTA_001"
)

// å‰ç«¯æ ¹æ®é”™è¯¯ç æ˜¾ç¤ºå›½é™…åŒ–æ¶ˆæ¯
```

---

### P3-3: æ›´ä¸¥æ ¼çš„ç±»å‹å®šä¹‰

```go
type RecurrenceType string

const (
	RecurrenceTypeDaily   RecurrenceType = "daily"
	RecurrenceTypeWeekly  RecurrenceType = "weekly"
	RecurrenceTypeMonthly RecurrenceType = "monthly"
)

func (rt RecurrenceType) IsValid() bool {
	switch rt {
	case RecurrenceTypeDaily, RecurrenceTypeWeekly, RecurrenceTypeMonthly:
		return true
	default:
		return false
	}
}

type RecurrenceRule struct {
	Type     RecurrenceType `json:"type"`
	Interval int            `json:"interval"`
	// ...
}
```

---

### P3-4: æé«˜æµ‹è¯•è¦†ç›–ç‡

ç›®æ ‡ï¼š70%+ è¦†ç›–ç‡

```bash
# å®‰è£…è¦†ç›–ç‡å·¥å…·
go install github.com/glebarez/go_plugin@latest

# ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š
go test -coverprofile=coverage.out ./...
go tool cover -html=coverage.out
```

---

### P3-5: ç»Ÿä¸€æ—¥å¿—è§„èŒƒ

```go
// ä½¿ç”¨ç»“æ„åŒ–æ—¥å¿—
slog.Info("schedule created",
	"user_id", user.ID,
	"schedule_id", schedule.ID,
	"title", schedule.Title,
)

// é¿å…ä½¿ç”¨
fmt.Printf("Schedule created: %v\n", schedule)
```

---

### P3-6: æ·»åŠ ä»£ç æ³¨é‡Š

```go
// ScheduleParser converts natural language input into structured schedule information.
//
// It uses LLM to understand complex patterns like "every Monday at 3pm" or "next Friday morning".
// The parser is timezone-aware and converts all times to UTC for storage.
//
// Example:
//   parser := NewParser(llmService, "Asia/Shanghai")
//   result, err := parser.Parse(ctx, "æ˜å¤©ä¸‹åˆ3ç‚¹å¼€ä¼š")
type ScheduleParser struct {
	// ...
}
```

---

### P3-7: æ·»åŠ  Proto éªŒè¯

å®‰è£… `protoc-gen-validate`:

```bash
go install github.com/envoyproxy/protoc-gen-validate@latest
```

æ·»åŠ éªŒè¯è§„åˆ™ï¼š

```proto
import "validate/validate.proto";

message Schedule {
  string title = 1 [(validate.rules).string = {min_len: 1, max_len: 200}];
  int64 start_ts = 2 [(validate.rules).int64.gt = 0];
  int64 end_ts = 3 [(validate.rules).int64.gt = 0];
}
```

---

### P3-8: æ¶ˆé™¤ä»£ç é‡å¤

æå–è¾…åŠ©å‡½æ•°ï¼š

```go
// marshalReminders converts protobuf reminders to JSON
func marshalReminders(reminders []*v1pb.Reminder) (string, error) {
	if len(reminders) == 0 {
		return "", nil
	}
	data, err := json.Marshal(reminders)
	if err != nil {
		return "", fmt.Errorf("failed to marshal reminders: %w", err)
	}
	return string(data), nil
}

// unmarshalReminders converts JSON to protobuf reminders
func unmarshalReminders(data string) ([]*v1pb.Reminder, error) {
	if data == "" {
		return nil, nil
	}
	var reminders []*v1pb.Reminder
	if err := json.Unmarshal([]byte(data), &reminders); err != nil {
		return nil, fmt.Errorf("failed to unmarshal reminders: %w", err)
	}
	return reminders, nil
}
```

---

### P3-9: æ¸…ç†æœªä½¿ç”¨ä»£ç 

```bash
# Go
go vet ./...
goimports -w .

# TypeScript
npm run lint
npx eslint --fix web/src/
```

---

### P3-10: æ”¹è¿›é…ç½®ç®¡ç†

ä½¿ç”¨é…ç½®æ˜ å°„è¡¨ï¼š

```go
var providerConfigMap = map[string]struct {
	apiKeyField   *string
	baseURLField  *string
	modelField    *string
}{
	"siliconflow": {
		apiKeyField:  &profile.AISiliconFlowAPIKey,
		baseURLField: &profile.AISiliconFlowBaseURL,
		modelField:   &profile.AISiliconFlowModel,
	},
	"openai": {
		apiKeyField:  &profile.AIOpenAIAPIKey,
		baseURLField: &profile.AIOpenAIBaseURL,
		modelField:   &profile.AIOpenAIModel,
	},
	// ...
}
```

---

## æµ‹è¯•éªŒè¯æ¸…å•

### å•å…ƒæµ‹è¯•

- [ ] `plugin/ai/llm_test.go` - æ‰€æœ‰æµ‹è¯•é€šè¿‡
- [ ] `plugin/ai/reranker_test.go` - è¶…æ—¶æµ‹è¯•é€šè¿‡
- [ ] `plugin/ai/schedule/recurrence_test.go` - æ—¶åŒºæµ‹è¯•é€šè¿‡
- [ ] `server/router/api/v1/ai_service_test.go` - è¾“å…¥éªŒè¯æµ‹è¯•é€šè¿‡
- [ ] `server/router/api/v1/schedule_service_test.go` - åˆ†é¡µæµ‹è¯•é€šè¿‡

### é›†æˆæµ‹è¯•

- [ ] `store/test/memo_embedding_test.go` - å‘é‡æœç´¢æµ‹è¯•é€šè¿‡
- [ ] æ•°æ®åº“è¿ç§»å›æ»šæµ‹è¯•é€šè¿‡
- [ ] API ç«¯åˆ°ç«¯æµ‹è¯•é€šè¿‡

### æ€§èƒ½æµ‹è¯•

- [ ] é€Ÿç‡é™åˆ¶åŠŸèƒ½æ­£å¸¸
- [ ] é…é¢æ‰£å‡æ­£ç¡®
- [ ] å¹¶å‘åœºæ™¯æµ‹è¯•é€šè¿‡
- [ ] å†…å­˜æ³„æ¼æ£€æµ‹é€šè¿‡

### å‰ç«¯æµ‹è¯•

- [ ] TypeScript ç¼–è¯‘æ— é”™è¯¯
- [ ] ESLint æ£€æŸ¥é€šè¿‡
- [ ] æ—¶åŒºåˆ‡æ¢æµ‹è¯•é€šè¿‡
- [ ] è™šæ‹Ÿæ»šåŠ¨æµ‹è¯•é€šè¿‡

---

## ä¿®å¤è¿›åº¦è·Ÿè¸ª

| ID | é—®é¢˜æè¿° | ä¼˜å…ˆçº§ | çŠ¶æ€ | è´Ÿè´£äºº | é¢„ä¼°æ—¶é—´ |
|----|---------|--------|------|--------|----------|
| P0-1 | Goroutine æ³„æ¼ | ğŸ”´ | å¾…ä¿®å¤ | - | 30åˆ†é’Ÿ |
| P0-2 | Context å–æ¶ˆ | ğŸ”´ | å¾…ä¿®å¤ | - | 20åˆ†é’Ÿ |
| P1-1 | æ—¶åŒºå¤„ç† | ğŸŸ  | å¾…ä¿®å¤ | - | 45åˆ†é’Ÿ |
| P1-2 | å®ä¾‹å±•å¼€ | ğŸŸ  | å¾…ä¿®å¤ | - | 40åˆ†é’Ÿ |
| P1-3 | è¾“å…¥éªŒè¯ | ğŸŸ  | å¾…ä¿®å¤ | - | 30åˆ†é’Ÿ |
| P1-4 | SQL å ä½ç¬¦ | ğŸŸ  | å¾…ä¿®å¤ | - | 25åˆ†é’Ÿ |
| P1-5 | å‰ç«¯æ—¶åŒº | ğŸŸ  | å¾…ä¿®å¤ | - | 1å°æ—¶ |
| P1-6 | HTTP è¶…æ—¶ | ğŸŸ  | å¾…ä¿®å¤ | - | 15åˆ†é’Ÿ |
| P1-7 | å›æ»šè„šæœ¬ | ğŸŸ  | å¾…ä¿®å¤ | - | 50åˆ†é’Ÿ |
| P1-8 | é€Ÿç‡é™åˆ¶ | ğŸŸ  | å¾…ä¿®å¤ | - | 1.5å°æ—¶ |

**æ€»è®¡é¢„ä¼°æ—¶é—´**: P0 (50åˆ†é’Ÿ) + P1 (6å°æ—¶) + P2 (6.5å°æ—¶) + P3 (4å°æ—¶) = **çº¦ 17 å°æ—¶**

---

## ä¿®å¤å»ºè®®ä¼˜å…ˆçº§

**ç¬¬ä¸€é˜¶æ®µï¼ˆæœ¬å‘¨ï¼‰**: ä¿®å¤æ‰€æœ‰ P0 é—®é¢˜
- P0-1: Goroutine æ³„æ¼
- P0-2: Context å–æ¶ˆ

**ç¬¬äºŒé˜¶æ®µï¼ˆæœ¬æœˆï¼‰**: ä¿®å¤æ‰€æœ‰ P1 é—®é¢˜
- P1-1 è‡³ P1-8

**ç¬¬ä¸‰é˜¶æ®µï¼ˆä¸‹å­£åº¦ï¼‰**: å®æ–½ P2 æ€§èƒ½ä¼˜åŒ–
- æ ¹æ®å®é™…æ€§èƒ½æµ‹è¯•ç»“æœé€‰æ‹©

**ç¬¬å››é˜¶æ®µï¼ˆæŒç»­ï¼‰**: P3 ä»£ç è´¨é‡æ”¹è¿›
- ä½œä¸ºæŠ€æœ¯å€ºåŠ¡é€æ­¥å¿è¿˜

---

## æ³¨æ„äº‹é¡¹

1. **æ¯ä¸ªä¿®å¤å‰å…ˆåˆ›å»ºåˆ†æ”¯**: `fix/issue-{ID}-{short-description}`
2. **æ¯ä¸ªä¿®å¤éƒ½éœ€è¦æµ‹è¯•**: å•å…ƒæµ‹è¯• + é›†æˆæµ‹è¯•
3. **ä¿®å¤åæ›´æ–°æ–‡æ¡£**: å¦‚æœ‰ API å˜æ›´
4. **æäº¤å‰ä»£ç å®¡æŸ¥**: è‡³å°‘ä¸€äººå®¡æŸ¥
5. **é€æ­¥åˆå¹¶**: ä¸è¦ä¸€æ¬¡æ€§åˆå¹¶æ‰€æœ‰ä¿®å¤

---

**æ–‡æ¡£ç‰ˆæœ¬**: 1.0
**æœ€åæ›´æ–°**: 2026-01-20
**ç»´æŠ¤è€…**: å¼€å‘å›¢é˜Ÿ
