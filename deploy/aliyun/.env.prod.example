# ==============================================================================
# Memos 生产环境配置 (单机 2C2G 部署)
# ==============================================================================
# 使用:
#   1. 复制: cp .env.prod.example .env.prod
#   2. 修改密码和 API Keys
#   3. 不要将 .env.prod 提交到 Git

# ==============================================================================
# [必填] 服务配置
# ==============================================================================

# 服务端口
MEMOS_PORT=5230

# 时区
TZ=Asia/Shanghai

# 实例 URL (公网访问地址，用于 API 回调)
MEMOS_INSTANCE_URL=http://your-server-ip:5230

# ==============================================================================
# [必填] PostgreSQL 配置
# ==============================================================================

POSTGRES_DB=memos
POSTGRES_USER=memos
POSTGRES_PASSWORD=your_secure_password

# 外部数据库连接 (可选，需要 pgAdmin/DataGrip 时开启)
# POSTGRES_PORT_MAPPING=127.0.0.1:25432:5432

# ==============================================================================
# [必填] AI 功能 - API Keys
# ==============================================================================

MEMOS_AI_ENABLED=true
MEMOS_AI_SILICONFLOW_API_KEY=sk-your-siliconflow-key
MEMOS_AI_DEEPSEEK_API_KEY=sk-your-deepseek-key

# ==============================================================================
# [可选] AI 模型配置
# ==============================================================================
#
# 系统使用 4 类模型，各司其职：
#
# ┌──────────────┬──────────────────────────────────────────────────────────────┐
# │ 模型类型     │ 用途说明                                                     │
# ├──────────────┼──────────────────────────────────────────────────────────────┤
# │ 对话 (LLM)   │ Agent 核心能力：对话、推理、工具调用                         │
# │              │ 场景：日程创建、笔记问答、综合分析                           │
# ├──────────────┼──────────────────────────────────────────────────────────────┤
# │ 向量 (Embed) │ 文本向量化：将笔记转为向量存入 pgvector                      │
# │              │ 场景：语义搜索 "找关于项目管理的笔记"                        │
# ├──────────────┼──────────────────────────────────────────────────────────────┤
# │ 意图 (Intent)│ 用户输入分类：判断是创建/查询/修改日程                       │
# │              │ 场景：区分 "明天开会" vs "明天有空吗"                        │
# ├──────────────┼──────────────────────────────────────────────────────────────┤
# │ 重排 (Rerank)│ 搜索结果优化：对向量召回结果精排                             │
# │              │ 场景：提升搜索准确率，过滤无关结果                           │
# └──────────────┴──────────────────────────────────────────────────────────────┘
#
# 默认配置 (推荐):
#
# ┌──────────────┬────────────────┬──────────────────────────┬─────────────────┐
# │ 模型类型     │ Provider       │ 模型                     │ 使用的 API Key  │
# ├──────────────┼────────────────┼──────────────────────────┼─────────────────┤
# │ 对话 (LLM)   │ deepseek       │ deepseek-chat            │ DEEPSEEK_API_KEY│
# │ 向量 (Embed) │ siliconflow    │ BAAI/bge-m3              │ SILICONFLOW_KEY │
# │ 意图 (Intent)│ siliconflow    │ Qwen/Qwen2.5-7B-Instruct │ SILICONFLOW_KEY │
# │ 重排 (Rerank)│ siliconflow    │ BAAI/bge-reranker-v2-m3  │ SILICONFLOW_KEY │
# └──────────────┴────────────────┴──────────────────────────┴─────────────────┘
#
# 为什么这样分配？
# - DeepSeek: 对话能力强、推理深、工具调用稳定，适合做主 LLM
# - SiliconFlow: 向量/重排模型全、价格低、国内访问快，适合做基础设施
# - 意图分类用轻量 7B 模型：响应快(<500ms)、成本低、准确率高

# -----------------------------------------------------------------------------
# 自定义 Provider (按需修改)
# -----------------------------------------------------------------------------

# 向量 Provider: siliconflow (默认) | openai | ollama
# MEMOS_AI_EMBEDDING_PROVIDER=siliconflow

# 对话 Provider: deepseek (默认) | openai | ollama | siliconflow
# MEMOS_AI_LLM_PROVIDER=deepseek

# -----------------------------------------------------------------------------
# 自定义模型 (按需修改)
# -----------------------------------------------------------------------------

# 向量模型 (需与 Provider 匹配)
# MEMOS_AI_EMBEDDING_MODEL=BAAI/bge-m3

# 重排模型 (固定使用 SiliconFlow)
# MEMOS_AI_RERANK_MODEL=BAAI/bge-reranker-v2-m3

# 对话模型 (需与 Provider 匹配)
# MEMOS_AI_LLM_MODEL=deepseek-chat

# 意图分类模型 (固定使用 SiliconFlow，无需配置)
# 默认: Qwen/Qwen2.5-7B-Instruct

# ==============================================================================
# [可选] 其他 Provider API Keys
# ==============================================================================

# OpenAI (如需使用 gpt-4o 等模型)
# MEMOS_AI_OPENAI_API_KEY=sk-your-openai-key

# Ollama (本地部署)
# MEMOS_AI_OLLAMA_BASE_URL=http://localhost:11434

# ==============================================================================
# [可选] 附件处理
# ==============================================================================

# OCR 图片文字提取 (需安装 Tesseract)
# MEMOS_OCR_ENABLED=true
# MEMOS_OCR_LANGUAGES=chi_sim+eng

# 文档文本提取 (需部署 Apache Tika)
# MEMOS_TEXTEXTRACT_ENABLED=true
# MEMOS_TEXTEXTRACT_TIKA_URL=http://localhost:9998

# ==============================================================================
# [可选] Docker 镜像配置
# ==============================================================================

# Memos 镜像 (可选值)
# - 官方镜像: ghcr.io/usememos/memos:latest
# - 自定义镜像: ghcr.io/hry/memos:latest
# - Docker Hub: neosmemo/memos:latest
USER_IMAGE=ghcr.io/hry/memos:latest

# PostgreSQL 镜像 (默认 pgvector/pgvector:pg16)
# POSTGRES_IMAGE=pgvector/pgvector:pg16

# ==============================================================================
# 配置方案速查
# ==============================================================================
#
# 方案 A: SiliconFlow + DeepSeek [推荐]
# -------------------------------------
# 成本最优，国内访问稳定
# MEMOS_AI_SILICONFLOW_API_KEY=sk-xxx
# MEMOS_AI_DEEPSEEK_API_KEY=sk-xxx
#
# 方案 B: 纯 SiliconFlow
# ----------------------
# 单一供应商，管理简单
# MEMOS_AI_LLM_PROVIDER=siliconflow
# MEMOS_AI_SILICONFLOW_API_KEY=sk-xxx
# MEMOS_AI_LLM_MODEL=Qwen/Qwen2.5-72B-Instruct
#
# 方案 C: OpenAI 全家桶
# --------------------
# 海外用户，追求效果
# MEMOS_AI_EMBEDDING_PROVIDER=openai
# MEMOS_AI_LLM_PROVIDER=openai
# MEMOS_AI_OPENAI_API_KEY=sk-xxx
# MEMOS_AI_EMBEDDING_MODEL=text-embedding-3-small
# MEMOS_AI_LLM_MODEL=gpt-4o
#
# 方案 D: 本地 Ollama
# ------------------
# 完全离线，数据私密
# MEMOS_AI_EMBEDDING_PROVIDER=ollama
# MEMOS_AI_LLM_PROVIDER=ollama
# MEMOS_AI_OLLAMA_BASE_URL=http://localhost:11434
# MEMOS_AI_EMBEDDING_MODEL=nomic-embed-text
# MEMOS_AI_LLM_MODEL=llama3.1
